{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System packages\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "# Data related\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# sklearn tools \n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, DictVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import custom functions\n",
    "from utils_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/train_variants_text.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample =df.groupby('Class').apply(lambda x: x.sample(frac=0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-d01645b86ec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m sample =sample.drop([sample.columns[1], \n\u001b[1;32m      2\u001b[0m                      \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                      sample.columns[5]], \n\u001b[0m\u001b[1;32m      4\u001b[0m                     axis='columns')\n\u001b[1;32m      5\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3957\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "sample =sample.drop([sample.columns[1], \n",
    "                     sample.columns[2], \n",
    "                     sample.columns[5]], \n",
    "                    axis='columns')\n",
    "sample.dropna(subset=['Text'])\n",
    "sample.head(1)\n",
    "sample.to_csv('../data/processed/train_variants_text_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('../data/processed/train_variants_text_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NF2</td>\n",
       "      <td>L46R</td>\n",
       "      <td>Neurofibromatosis type 2 (NF2) is a multiple n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FGFR2</td>\n",
       "      <td>E219K</td>\n",
       "      <td>Introduction  Melanoma is the most lethal of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>BRCA1</td>\n",
       "      <td>F1704S</td>\n",
       "      <td>Abstract  The BRCA1 gene from individuals at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>TP53</td>\n",
       "      <td>R337H</td>\n",
       "      <td>The tumor suppressor protein p53 is a transcri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>TSC2</td>\n",
       "      <td>E75G</td>\n",
       "      <td>Tuberous sclerosis complex (TSC) is an autosom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class   Gene Variation                                               Text\n",
       "0      1    NF2      L46R  Neurofibromatosis type 2 (NF2) is a multiple n...\n",
       "1      1  FGFR2     E219K  Introduction  Melanoma is the most lethal of a...\n",
       "2      1  BRCA1    F1704S   Abstract  The BRCA1 gene from individuals at ...\n",
       "3      1   TP53     R337H  The tumor suppressor protein p53 is a transcri...\n",
       "4      1   TSC2      E75G  Tuberous sclerosis complex (TSC) is an autosom..."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split sample data into train and validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = split_data(sample,\n",
    "                                      'Text',\n",
    "                                      'Class',\n",
    "                                      0.1,\n",
    "                                      0,\n",
    "                                      stratify='Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first y_tr and X_tr\n",
    "#print(y_tr[0], \"-is the predicted Class for text -\", X_tr[0],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bag of words\n",
    "Here we will use \n",
    " * CountVectorizer: Counts the number of times a word appears in the text\n",
    " * TfidfVectorizer: Weighs the words according to the importance of the word in the context of whole collection\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found w2vmodel\n"
     ]
    }
   ],
   "source": [
    "# Use document df\n",
    "w2vec = get_word2vec(\n",
    "    MySentences(\n",
    "        sample['Text'].values, \n",
    "    ),\n",
    "    'w2vmodel'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Bag of words + Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Naive Bayes classifier for multinomial models\n",
    "Suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer(preprocessor=clean_text_stemmed, stop_words =stop_words)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf',  MultinomialNB())])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44776119402985076\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_tr, y_tr)  \n",
    "predicted = clf.predict(X_val)\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)\n",
    "#print(classification_report(y_val, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 SGD \n",
    "\n",
    "This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning, see the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer(preprocessor=clean_text_stemmed, stop_words =stop_words)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf',  SGDClassifier(n_jobs=))])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4925373134328358\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_tr, y_tr)  \n",
    "predicted = clf.predict(X_val)\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without text cleaning\n",
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf',  xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42))])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5223880597014925\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_tr, y_tr)  \n",
    "predicted = clf.predict(X_val)\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With text cleaning\n",
    "clf = Pipeline([('vect', CountVectorizer(preprocessor=clean_text_stemmed, stop_words =stop_words)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf',  xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42))])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5671641791044776\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_tr, y_tr)  \n",
    "predicted = clf.predict(X_val)\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Gene + Variation + xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Class'] = sample['Class'].astype(int)\n",
    "sample['Gene'] = sample['Gene'].astype(str)\n",
    "sample['Variation'] = sample['Variation'].astype(str)\n",
    "\n",
    "y= sample['Class']\n",
    "X= sample.drop('Class',axis =1)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X,\n",
    "                                            y,\n",
    "                                            test_size=0.2,\n",
    "                                            stratify=y,\n",
    "                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline= make_pipeline(\n",
    "    # combine features\n",
    "    make_union(\n",
    "        make_pipeline(\n",
    "            PandasSelector([\"Gene\",\"Variation\"]),\n",
    "            PandasToDict(),\n",
    "            DictVectorizer(sparse=False)\n",
    "            # select categorical data\n",
    "        )\n",
    "    \n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(processing_pipeline, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('pandasselector', PandasSelector(columns=['Gene', 'Variation'])), ('pandastodict', PandasToDict()), ('dictvectorizer', DictVectori...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42105263157894735\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_val)\n",
    "\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 TFIDF(Text) + xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline= make_pipeline(\n",
    "    # combine features\n",
    "    make_union(\n",
    "        \n",
    "        make_pipeline(\n",
    "            ItemSelector(key='Text'),\n",
    "            Converter(),\n",
    "            TfidfVectorizer()\n",
    "                    )\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('itemselector', ItemSelector(key='Text')), ('converter', Converter()), ('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(processing_pipeline, clf)\n",
    "model.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_val)\n",
    "\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 OneHot(Gene) + TFIDF(Text)  + xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline= make_pipeline(\n",
    "    # combine features\n",
    "    make_union(\n",
    "        \n",
    "        make_pipeline(\n",
    "            ItemSelector(key='Text'),\n",
    "            Converter(),\n",
    "            TfidfVectorizer()\n",
    "                    ),    \n",
    "        make_pipeline(\n",
    "            ItemSelector(key=\"Gene\"),\n",
    "            Converter(),\n",
    "            OneHotEncoder()\n",
    "    )\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pipeline-1', Pipeline(memory=None,\n",
       "     steps=[('itemselector', ItemSelector(key='Text')), ('converter', Converter()), ('tfidfvectorizer', TfidfVectorizer(analyzer='word', bina...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(processing_pipeline, clf)\n",
    "model.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6240601503759399\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_val)\n",
    "\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 OneHot(Variation) + TFIDF(Text) + xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline= make_pipeline(\n",
    "    # combine features\n",
    "    make_union(    \n",
    "        make_pipeline(\n",
    "            ItemSelector(key='Text'),\n",
    "            Converter(),\n",
    "            TfidfVectorizer()\n",
    "                    ),\n",
    "        make_pipeline(\n",
    "            ItemSelector(key=\"Variation\"),\n",
    "            Converter(),\n",
    "            OneHotEncoder()\n",
    "    )\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pipeline-1', Pipeline(memory=None,\n",
       "     steps=[('itemselector', ItemSelector(key='Text')), ('converter', Converter()), ('tfidfvectorizer', TfidfVectorizer(analyzer='word', bina...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(processing_pipeline, clf)\n",
    "model.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_val)\n",
    "\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(processing_pipeline,clf,X_tr,y_tr,X_val,y_val):\n",
    "    model = make_pipeline(processing_pipeline, clf)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    predicted = model.predict(X_val)\n",
    "    acc=np.mean(predicted == y_val)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict(processing_pipeline,clf,X_tr,y_tr,X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7 OneHot(Variation) + OneHot(Gene) + TFIDF(Text)  + xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline2= make_pipeline(\n",
    "    # combine features\n",
    "    make_union(\n",
    "        \n",
    "        make_pipeline(\n",
    "            ItemSelector(key='Text'),\n",
    "            Converter(),\n",
    "            TfidfVectorizer()\n",
    "                    ),    \n",
    "        make_pipeline(\n",
    "            ItemSelector(key=\"Gene\"),\n",
    "            Converter(),\n",
    "            OneHotEncoder()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            ItemSelector(key=\"Variation\"),\n",
    "            Converter(),\n",
    "            OneHotEncoder()\n",
    "    )\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pipeline-1', Pipeline(memory=None,\n",
       "     steps=[('itemselector', ItemSelector(key='Text')), ('converter', Converter()), ('tfidfvectorizer', TfidfVectorizer(analyzer='word', bina...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = make_pipeline(processing_pipeline2, clf)\n",
    "model2.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6240601503759399\n"
     ]
    }
   ],
   "source": [
    "predicted2 = model2.predict(X_val)\n",
    "\n",
    "acc2=np.mean(predicted2 == y_val)\n",
    "print(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(664, 1)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_selector = ItemSelector(key='Gene')\n",
    "df_gene = gene_selector.fit_transform(sample)\n",
    "df_gene.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Word2vec + Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Document-trained w2vec + xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', MeanEmbeddingVectorizer(w2vec)),\n",
    "                ('clf',  xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42))])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4626865671641791\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_tr, y_tr)  \n",
    "predicted = clf.predict(X_val)\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
