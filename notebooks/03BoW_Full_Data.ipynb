{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# System packages\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "# Data related\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pprint as pp\n",
    "\n",
    "# sklearn \n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict,cross_val_score,  StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scikitplot.plotters as skplt\n",
    "\n",
    "# nlp\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# models\n",
    "import xgboost as xgb\n",
    "import eli5\n",
    "from eli5.explain import explain_weights\n",
    "from eli5.formatters import explain_weights_df\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add utils_functions.py as a dataset\n",
    "# Import module \n",
    "from shutil import copyfile\n",
    "\n",
    "# Copy our file into the working directory (make sure it has .py suffix)\n",
    "copyfile(src = \"../input/utils-functions/utils_functions.py\", dst = '/kaggle/working/utils_functions.py')\n",
    "from utils_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/processed/train_variants_text.csv')\n",
    "df=df.dropna(subset=['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df['Class'].astype(int)\n",
    "df['Gene'] = df['Gene'].astype(str)\n",
    "df['Variation'] = df['Variation'].astype(str)\n",
    "\n",
    "y= df['Class']\n",
    "X= df.drop(['Class','ID'],axis =1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Bag-of-words 1 Group+xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train amd Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = split_data(df,\n",
    "                                      'Text',\n",
    "                                      'Class',\n",
    "                                      0.1,\n",
    "                                      0,\n",
    "                                      stratify='Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer(preprocessor=clean_text_stemmed, stop_words =stop_words)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf',  xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42))])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_tr, y_tr)  \n",
    "predicted = clf.predict(X_val)\n",
    "acc=np.mean(predicted == y_val)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = test.Text.values\n",
    "X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te = clf.predict_proba(X_te)\n",
    "y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Bag-of-words *3 groups +xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one dataframe column for vectorization\n",
    "def build_preprocessor(df,field):\n",
    "    field_idx = list(df.columns).index(field)\n",
    "    return lambda x: default_preprocessor(x[field_idx])\n",
    "default_preprocessor = CountVectorizer().build_preprocessor()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = FeatureUnion([\n",
    "    ('Variation',TfidfVectorizer(preprocessor=build_preprocessor(X,'Variation'))),\n",
    "        ('Gene',TfidfVectorizer(preprocessor=build_preprocessor(X,'Gene'))),\n",
    "        ('Text',TfidfVectorizer(preprocessor=build_preprocessor(X,'Text'))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v = vectorizer.fit_transform(X.values)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_v,\n",
    "                                            y,\n",
    "                                            test_size=0.2,\n",
    "                                            stratify=y,\n",
    "                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "model.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score \n",
    "model.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = explain_weights_df(model, vec=vectorizer, top=10, feature_filter=lambda x: x != '<BIAS>')           \n",
    "df_name.to_csv('../data/features/20190609full_union_3groups_tfidf_feature_weights.csv')\n",
    "df_name.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing individual predictions. Let's check some predictions from the validation set. You see a summary of various vectorizer's contribution at the top, and then below you can see features highlighed in text.\n",
    "eli5.show_prediction(model, doc=X.values[1], vec=vectorizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
